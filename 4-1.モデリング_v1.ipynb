{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e1c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 0. Imports & 定数 =========\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, f1_score, accuracy_score\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "    f1_score, accuracy_score\n",
    ")\n",
    "import os, random\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, train_test_split, GroupShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, joblib\n",
    "import re\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import platform\n",
    "\n",
    "# ==== Permutation Importance 用ユーティリティ ====\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import get_scorer\n",
    "import json, joblib\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0df7a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_DIR: /Users/okada1015/Desktop/マリサ/marisa/output\n",
      "OUTPUT_DIR: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1\n",
      "MODEL_DIR: /Users/okada1015/Desktop/マリサ/marisa/model\n"
     ]
    }
   ],
   "source": [
    "# === 入出力ディレクトリ設定 ===\n",
    "# 入力は project_root/inputs\n",
    "INPUT_DIR = os.path.join(os.getcwd(), \"output\")\n",
    "# 出力は project_root/outputs\n",
    "OUTPUT_DIR = os.path.join(os.getcwd(), \"output_model_v1\")\n",
    "MODEL_DIR  = os.path.join(os.getcwd(), \"model\")\n",
    "# ディレクトリが無ければ作成\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(\"INPUT_DIR:\", INPUT_DIR)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n",
    "print(\"MODEL_DIR:\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f09c52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========= 1. 乱数固定（決定性の土台） =========\n",
    "SEED = 42  # ←固定。変えれば分割・学習が変わるので注意\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"  # ※Jupyterではカーネル再起動が必要になる点に注意\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ========= 2. バージョン確認（任意） =========\n",
    "print(\"Python:\", platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f5c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ========= 3. 保存先 =========\n",
    "# MODEL_DIR  = \"/Users/okada1015/Desktop/マリサ/model\"\n",
    "# OUTPUT_DIR = \"/Users/okada1015/Desktop/マリサ/output\"\n",
    "# os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebfd96c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/3809316497.py:16: DtypeWarning: Columns (21,33,44,45,75,77,78,91,92,93,94,100,106,110,111,120,122,155,159,209,210,211,221,224,225,226,227,228,230,238,240,241,242,243,244,245,247,255,257,258,259,260,261,262,263,264,307,308,311,312,314,315,317,335,336,337,341,343,346,354,355,356,357,359,383) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_m = pd.read_csv(os.path.join(INPUT_DIR, \"3.ASSESSMENT_REPORTS_WITH_FLG_EDA_mansion.csv\"),\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/3809316497.py:19: DtypeWarning: Columns (28,33,44,45,46,54,55,56,57,58,59,68,70,74,77,78,91,92,93,94,100,104,105,106,107,108,120,121,155,159,209,210,211,221,224,226,227,228,230,238,240,241,242,243,244,245,246,247,254,255,257,258,259,260,261,262,263,302,303,307,308,309,310,311,312,314,315,317,335,336,337,341,343,346,354,355,356,357,359) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_l = pd.read_csv(os.path.join(INPUT_DIR, \"3.ASSESSMENT_REPORTS_WITH_FLG_EDA_land.csv\"),\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/3809316497.py:22: DtypeWarning: Columns (28,33,44,45,46,54,55,56,57,58,59,60,68,70,75,77,78,91,92,93,94,100,106,120,122,126,127,155,159,209,210,211,226,228,230,241,243,245,247,255,258,259,260,261,262,264,302,303,311,312,313,314,315,317,335,336,337,341,343,346,354,355,356,357,359) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_h = pd.read_csv(os.path.join(INPUT_DIR, \"3.ASSESSMENT_REPORTS_WITH_FLG_EDA_house.csv\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (113031, 394) (24658, 393) (69099, 395)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ========= 4. データ読み込み =========\n",
    "# 北→南リスト（順序固定のため）\n",
    "PREF_NORTH_TO_SOUTH = [\n",
    "    \"北海道\", \"青森県\", \"岩手県\", \"宮城県\", \"秋田県\", \"山形県\", \"福島県\",\n",
    "    \"茨城県\", \"栃木県\", \"群馬県\", \"埼玉県\", \"千葉県\", \"東京都\", \"神奈川県\",\n",
    "    \"新潟県\", \"富山県\", \"石川県\", \"福井県\", \"山梨県\", \"長野県\",\n",
    "    \"岐阜県\", \"静岡県\", \"愛知県\", \"三重県\", \"滋賀県\", \"京都府\", \"大阪府\", \"兵庫県\", \"奈良県\", \"和歌山県\",\n",
    "    \"鳥取県\", \"島根県\", \"岡山県\", \"広島県\", \"山口県\",\n",
    "    \"徳島県\", \"香川県\", \"愛媛県\", \"高知県\",\n",
    "    \"福岡県\", \"佐賀県\", \"長崎県\", \"熊本県\", \"大分県\", \"宮崎県\", \"鹿児島県\",\n",
    "    \"沖縄県\"\n",
    "]\n",
    "dtype_pref = CategoricalDtype(categories=PREF_NORTH_TO_SOUTH, ordered=True)\n",
    "\n",
    "#マンション\n",
    "df_m = pd.read_csv(os.path.join(INPUT_DIR, \"3.ASSESSMENT_REPORTS_WITH_FLG_EDA_mansion.csv\"),\n",
    "                   encoding=\"utf-8-sig\", dtype={\"PREFECTURE\": \"string\"})\n",
    "#土地\n",
    "df_l = pd.read_csv(os.path.join(INPUT_DIR, \"3.ASSESSMENT_REPORTS_WITH_FLG_EDA_land.csv\"),\n",
    "                   encoding=\"utf-8-sig\", dtype={\"PREFECTURE\": \"string\"})\n",
    "#戸建\n",
    "df_h = pd.read_csv(os.path.join(INPUT_DIR, \"3.ASSESSMENT_REPORTS_WITH_FLG_EDA_house.csv\"),\n",
    "                   encoding=\"utf-8-sig\", dtype={\"PREFECTURE\": \"string\"})\n",
    "\n",
    "df_m[\"PREFECTURE\"] = df_m[\"PREFECTURE\"].astype(dtype_pref)\n",
    "df_l[\"PREFECTURE\"] = df_l[\"PREFECTURE\"].astype(dtype_pref)\n",
    "df_h[\"PREFECTURE\"] = df_h[\"PREFECTURE\"].astype(dtype_pref)\n",
    "print(\"shapes:\", df_m.shape, df_l.shape, df_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa069390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========= 5. 特徴量定義（あなたの元コードそのまま） =========\n",
    "# --- マンション (property_kind = 1) ---\n",
    "feature_cols_m = [\n",
    "'FLOOR_NUMBER_NUM','OWNER_SPACE_NUM','DIRECTION','DIRECTION_SIN','DIRECTION_COS','PREFECTURE','REGION',\n",
    "'LAND_PRIVILEGE_FLG','USAGE_AREA_REP','STRUCTURE_CAT','BUILDING_AGE','BUILDING_AGE_BIN','ABOUT_FLOOR_NUM',\n",
    "'ABOUT_UNIT_AMOUNT_NUM','ASSESS_SELL_PRICE_NUM','ASSESS_SELL_SQUARE_PRICE_NUM','ASSESS_SELL_TSUBO_PRICE_NUM',\n",
    "'ASSESS_SELL_TERM_NUM','VISIT_ASSESSMENT_FLG','ASSESS_PURCHASE_TERM_NUM','RENT_PRICE_FLG','INDICATE_COVER_STATISTICS',\n",
    "'INDICATE_MARKET_REPORTS','INDICATE_PRICE_HISTORY','INDICATE_PRICE_HISTORY_GRAPH','INDICATE_PRICE_HISTORY_SELF_COMPARE',\n",
    "'INDICATE_PRICE_HISTORY_AREA_COMPARE','INDICATE_AREA_HUMAN','INDICATE_AREA_HUMAN_AGE_GRAPH',\n",
    "'INDICATE_AREA_HUMAN_TRANSITION_GRAPH','INDICATE_COVER_MARKET','INDICATE_MARKET_SIZE','INDICATE_MARKET_SELL_TERM',\n",
    "'INDICATE_MORTGAGE_INTEREST','INDICATE_FLOATING_INTEREST_COMMENT','INTEREST_COMMENT_FLG','INDICATE_MEDIATION_CONTRACT',\n",
    "'EXPENSE1_SELL_PRICE_NUM','EXPENSE1_COMMISSION_RATE','EXPENSE1_COMMISSION_RATE_FLG','SP_READ_FLG','TUTORIAL_SP',\n",
    "'READ_FLG','READ_COUNT','CONTENT_COUNT','CONTENT_COUNT_FLG','TXT_NOTIFY_READ_AT','PRICE_DETAIL_COUNT',\n",
    "'MEDIATION_BUY_COUNT','MARKET_CONDITION_COUNT','CONSULTATION_MOVE_COUNT','TAX_ADVICE_COUNT','SELLING_EXPENSE_COUNT',\n",
    "'THANKS_COUNT','THX_NOTIFY_READ_AT_COUNT','HOPE_TEL_FLG_COUNT','TEL_NOTIFY_READ_AT_COUNT','MEETING_FLG_COUNT','MTG_NOTIFY_READ_AT_COUNT'\n",
    "]\n",
    "category_m = [\n",
    "'DIRECTION','PREFECTURE','REGION','LAND_PRIVILEGE_FLG','USAGE_AREA_REP','STRUCTURE_CAT','BUILDING_AGE_BIN',\n",
    "'VISIT_ASSESSMENT_FLG','RENT_PRICE_FLG','INDICATE_COVER_STATISTICS','INDICATE_MARKET_REPORTS','INDICATE_PRICE_HISTORY',\n",
    "'INDICATE_PRICE_HISTORY_GRAPH','INDICATE_PRICE_HISTORY_SELF_COMPARE','INDICATE_PRICE_HISTORY_AREA_COMPARE',\n",
    "'INDICATE_AREA_HUMAN','INDICATE_AREA_HUMAN_AGE_GRAPH','INDICATE_AREA_HUMAN_TRANSITION_GRAPH','INDICATE_COVER_MARKET',\n",
    "'INDICATE_MARKET_SIZE','INDICATE_MARKET_SELL_TERM','INDICATE_MORTGAGE_INTEREST','INDICATE_FLOATING_INTEREST_COMMENT',\n",
    "'INTEREST_COMMENT_FLG','INDICATE_MEDIATION_CONTRACT','EXPENSE1_COMMISSION_RATE_FLG','SP_READ_FLG','TUTORIAL_SP',\n",
    "'READ_FLG','CONTENT_COUNT_FLG','TXT_NOTIFY_READ_AT','THX_NOTIFY_READ_AT_COUNT','HOPE_TEL_FLG_COUNT',\n",
    "'TEL_NOTIFY_READ_AT_COUNT','MEETING_FLG_COUNT','MTG_NOTIFY_READ_AT_COUNT',\n",
    "]\n",
    "\n",
    "# --- 土地 (property_kind = 2) ---\n",
    "feature_cols_l = [\n",
    "'LAND_SPACE_NUM','PREFECTURE','REGION','LAND_PRIVILEGE_FLG','USAGE_AREA_REP','ASSESS_SELL_PRICE_NUM',\n",
    "'ASSESS_SELL_SQUARE_PRICE_NUM','ASSESS_SELL_TSUBO_PRICE_NUM','ASSESS_SELL_TERM_NUM','VISIT_ASSESSMENT_FLG',\n",
    "'ASSESS_PURCHASE_TERM_NUM','RENT_PRICE_FLG','INDICATE_COVER_STATISTICS','INDICATE_MARKET_REPORTS','INDICATE_PRICE_HISTORY',\n",
    "'INDICATE_PRICE_HISTORY_GRAPH','INDICATE_PRICE_HISTORY_SELF_COMPARE','INDICATE_PRICE_HISTORY_AREA_COMPARE',\n",
    "'INDICATE_AREA_HUMAN','INDICATE_AREA_HUMAN_AGE_GRAPH','INDICATE_AREA_HUMAN_TRANSITION_GRAPH','INDICATE_COVER_MARKET',\n",
    "'INDICATE_MARKET_SIZE','INDICATE_MARKET_SELL_TERM','INDICATE_MORTGAGE_INTEREST','INDICATE_FLOATING_INTEREST_COMMENT',\n",
    "'INTEREST_COMMENT_FLG','INDICATE_MEDIATION_CONTRACT','EXPENSE1_SELL_PRICE_NUM','EXPENSE1_COMMISSION_RATE',\n",
    "'EXPENSE1_COMMISSION_RATE_FLG','SP_READ_FLG','TUTORIAL_SP','READ_FLG','READ_COUNT','CONTENT_COUNT','CONTENT_COUNT_FLG',\n",
    "'TXT_NOTIFY_READ_AT','PRICE_DETAIL_COUNT','MEDIATION_BUY_COUNT','MARKET_CONDITION_COUNT','CONSULTATION_MOVE_COUNT',\n",
    "'TAX_ADVICE_COUNT','SELLING_EXPENSE_COUNT','THANKS_COUNT','THX_NOTIFY_READ_AT_COUNT','HOPE_TEL_FLG_COUNT',\n",
    "'TEL_NOTIFY_READ_AT_COUNT','MEETING_FLG_COUNT','MTG_NOTIFY_READ_AT_COUNT'\n",
    "]\n",
    "category_l = [\n",
    "'PREFECTURE','REGION','LAND_PRIVILEGE_FLG','USAGE_AREA_REP','VISIT_ASSESSMENT_FLG','RENT_PRICE_FLG',\n",
    "'INDICATE_COVER_STATISTICS','INDICATE_MARKET_REPORTS','INDICATE_PRICE_HISTORY','INDICATE_PRICE_HISTORY_GRAPH',\n",
    "'INDICATE_PRICE_HISTORY_SELF_COMPARE','INDICATE_PRICE_HISTORY_AREA_COMPARE','INDICATE_AREA_HUMAN',\n",
    "'INDICATE_AREA_HUMAN_AGE_GRAPH','INDICATE_AREA_HUMAN_TRANSITION_GRAPH','INDICATE_COVER_MARKET',\n",
    "'INDICATE_MARKET_SIZE','INDICATE_MARKET_SELL_TERM','INDICATE_MORTGAGE_INTEREST','INDICATE_FLOATING_INTEREST_COMMENT',\n",
    "'INTEREST_COMMENT_FLG','INDICATE_MEDIATION_CONTRACT','EXPENSE1_COMMISSION_RATE_FLG','SP_READ_FLG','READ_FLG',\n",
    "'CONTENT_COUNT_FLG','TXT_NOTIFY_READ_AT','HOPE_TEL_FLG_COUNT','TEL_NOTIFY_READ_AT_COUNT','MEETING_FLG_COUNT',\n",
    "'MTG_NOTIFY_READ_AT_COUNT',\n",
    "]\n",
    "\n",
    "# --- 戸建 (property_kind = 3) ---\n",
    "feature_cols_h = [\n",
    "'LAND_SPACE_NUM','BUILDING_SPACE_NUM','PREFECTURE','REGION','LAND_PRIVILEGE_FLG','USAGE_AREA_REP','STRUCTURE_CAT',\n",
    "'BUILDING_AGE','BUILDING_AGE_BIN','ABOUT_FLOOR_NUM','ASSESS_SELL_PRICE_NUM','ASSESS_SELL_SQUARE_PRICE_NUM',\n",
    "'ASSESS_SELL_TSUBO_PRICE_NUM','ASSESS_SELL_TERM_NUM','VISIT_ASSESSMENT_FLG','ASSESS_PURCHASE_TERM_NUM','RENT_PRICE_FLG',\n",
    "'INDICATE_COVER_STATISTICS','INDICATE_MARKET_REPORTS','INDICATE_PRICE_HISTORY','INDICATE_PRICE_HISTORY_GRAPH',\n",
    "'INDICATE_PRICE_HISTORY_SELF_COMPARE','INDICATE_PRICE_HISTORY_AREA_COMPARE','INDICATE_AREA_HUMAN',\n",
    "'INDICATE_AREA_HUMAN_AGE_GRAPH','INDICATE_AREA_HUMAN_TRANSITION_GRAPH','INDICATE_COVER_MARKET','INDICATE_MARKET_SIZE',\n",
    "'INDICATE_MARKET_SELL_TERM','INDICATE_MORTGAGE_INTEREST','INDICATE_FLOATING_INTEREST_COMMENT','INTEREST_COMMENT_FLG',\n",
    "'INDICATE_MEDIATION_CONTRACT','EXPENSE1_SELL_PRICE_NUM','EXPENSE1_COMMISSION_RATE','EXPENSE1_COMMISSION_RATE_FLG',\n",
    "'SP_READ_FLG','TUTORIAL_SP','READ_FLG','READ_COUNT','CONTENT_COUNT','CONTENT_COUNT_FLG','TXT_NOTIFY_READ_AT',\n",
    "'PRICE_DETAIL_COUNT','MEDIATION_BUY_COUNT','MARKET_CONDITION_COUNT','CONSULTATION_MOVE_COUNT','TAX_ADVICE_COUNT',\n",
    "'SELLING_EXPENSE_COUNT','THANKS_COUNT','THX_NOTIFY_READ_AT_COUNT','HOPE_TEL_FLG_COUNT','TEL_NOTIFY_READ_AT_COUNT',\n",
    "'MEETING_FLG_COUNT','MTG_NOTIFY_READ_AT_COUNT',\n",
    "]\n",
    "category_h = [\n",
    "'PREFECTURE','REGION','LAND_PRIVILEGE_FLG','USAGE_AREA_REP','STRUCTURE_CAT','BUILDING_AGE_BIN','VISIT_ASSESSMENT_FLG',\n",
    "'RENT_PRICE_FLG','INDICATE_COVER_STATISTICS','INDICATE_MARKET_REPORTS','INDICATE_PRICE_HISTORY',\n",
    "'INDICATE_PRICE_HISTORY_GRAPH','INDICATE_PRICE_HISTORY_SELF_COMPARE','INDICATE_PRICE_HISTORY_AREA_COMPARE',\n",
    "'INDICATE_AREA_HUMAN','INDICATE_AREA_HUMAN_AGE_GRAPH','INDICATE_AREA_HUMAN_TRANSITION_GRAPH','INDICATE_COVER_MARKET',\n",
    "'INDICATE_MARKET_SIZE','INDICATE_MARKET_SELL_TERM','INDICATE_MORTGAGE_INTEREST','INDICATE_FLOATING_INTEREST_COMMENT',\n",
    "'INTEREST_COMMENT_FLG','INDICATE_MEDIATION_CONTRACT','EXPENSE1_COMMISSION_RATE_FLG','SP_READ_FLG','TUTORIAL_SP',\n",
    "'READ_FLG','CONTENT_COUNT_FLG','TXT_NOTIFY_READ_AT','HOPE_TEL_FLG_COUNT','TEL_NOTIFY_READ_AT_COUNT',\n",
    "'MEETING_FLG_COUNT','MTG_NOTIFY_READ_AT_COUNT',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6aa3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 6. マッピング =========\n",
    "kind_to_df    = {1: df_m,             2: df_l,             3: df_h}\n",
    "kind_to_feats = {1: feature_cols_m,   2: feature_cols_l,   3: feature_cols_h}\n",
    "kind_to_cats  = {1: category_m,       2: category_l,       3: category_h}\n",
    "\n",
    "TARGET    = \"成約フラグ\"\n",
    "GROUP_COL = None  # 例: \"C_ID\" を使うなら \"C_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67b070c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 7. 決定性ヘルパー =========\n",
    "def normalize_categories(df: pd.DataFrame, categorical_cols):\n",
    "    \"\"\"\n",
    "    指定列を必ず category 化 → 未使用カテゴリ削除 → 水準の安定化（昇順 or 文字列昇順）\n",
    "    \"\"\"\n",
    "    g = df.copy()\n",
    "    for c in categorical_cols:\n",
    "        if c not in g.columns:\n",
    "            continue\n",
    "        # 何型でもまず category 化（0/1や*_COUNTなど数値でも）\n",
    "        g[c] = g[c].astype(\"category\")\n",
    "        # 未使用カテゴリを落とす\n",
    "        g[c] = g[c].cat.remove_unused_categories()\n",
    "        # カテゴリ水準を安定化（mixed型は文字列化してソート）\n",
    "        cats = list(g[c].cat.categories)\n",
    "        try:\n",
    "            cats_sorted = sorted(cats)\n",
    "        except TypeError:\n",
    "            cats_sorted = sorted(map(str, cats))\n",
    "        g[c] = g[c].cat.set_categories(cats_sorted, ordered=False)\n",
    "    return g\n",
    "\n",
    "\n",
    "def fingerprint_features(dfX: pd.DataFrame, cat_cols):\n",
    "    meta = {\n",
    "        \"columns\": list(dfX.columns),\n",
    "        \"dtypes\": {c: str(dfX[c].dtype) for c in dfX.columns},\n",
    "        \"cat_cols\": list(cat_cols),\n",
    "        \"cat_levels\": {\n",
    "            c: (list(dfX[c].cat.categories) if (c in dfX.columns and pd.api.types.is_categorical_dtype(dfX[c])) else None)\n",
    "            for c in dfX.columns\n",
    "        },\n",
    "    }\n",
    "    s = json.dumps(meta, ensure_ascii=False, sort_keys=True, default=str)\n",
    "    return hashlib.md5(s.encode()).hexdigest(), meta\n",
    "\n",
    "def model_hash(clf: LGBMClassifier):\n",
    "    dump = clf.booster_.dump_model(num_iteration=clf.best_iteration_)\n",
    "    s = json.dumps(dump, sort_keys=True)\n",
    "    return hashlib.md5(s.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b72f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 8. 分割ユーティリティ（元コード準拠＋決定性） =========\n",
    "def _build_cv(groups_available, n_splits=5, seed=SEED):\n",
    "    return GroupKFold(n_splits) if groups_available else StratifiedKFold(n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "def _split_train_test(df_kind, feature_cols, target_col, group_col=None, test_size=0.2, seed=SEED):\n",
    "    X_full = df_kind.reindex(columns=feature_cols).copy()\n",
    "    y_full = pd.Series(df_kind[target_col].astype(int).values, index=X_full.index, name=target_col)\n",
    "\n",
    "    groups = (df_kind[group_col].reindex(X_full.index).values\n",
    "              if group_col and group_col in df_kind.columns else None)\n",
    "\n",
    "    if groups is not None:\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "        tr_idx, te_idx = next(gss.split(X_full, y_full, groups))\n",
    "    else:\n",
    "        tr_idx, te_idx = train_test_split(\n",
    "            np.arange(len(X_full)), test_size=test_size, random_state=seed, stratify=y_full.values\n",
    "        )\n",
    "\n",
    "    X_tr, X_te = X_full.iloc[tr_idx].copy(), X_full.iloc[te_idx].copy()\n",
    "    y_tr, y_te = y_full.iloc[tr_idx].copy(), y_full.iloc[te_idx].copy()\n",
    "    grp_tr = (df_kind[group_col].iloc[tr_idx].values if groups is not None else None)\n",
    "    return X_tr, y_tr, grp_tr, X_te, y_te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8deb7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c3445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe49abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ========= 9. LightGBM 学習本体（決定性版） =========\n",
    "def train_eval_lgbm_no_leak(df_kind, feature_cols, category_cols,\n",
    "                            target_col=\"成約フラグ\", group_col=None,\n",
    "                            seed=SEED, n_splits=5, test_size=0.2):\n",
    "   # ---- split: 先に学習/テストを分ける ----\n",
    "    X_tr, y_tr, grp_tr, X_te, y_te = _split_train_test(\n",
    "        df_kind, feature_cols, target_col, group_col, test_size, seed\n",
    "    )\n",
    "\n",
    "    # ---- カテゴリ前処理（ここで必ず category 化＆水準固定）----\n",
    "    cat_cols = [c for c in category_cols if c in X_tr.columns]\n",
    "    X_tr = normalize_categories(X_tr, cat_cols)\n",
    "    X_te = normalize_categories(X_te, cat_cols)\n",
    "\n",
    "    # ---- CV 設定 ----\n",
    "    cv = _build_cv(grp_tr is not None, n_splits=n_splits, seed=seed)\n",
    "    oof = pd.Series(np.zeros(len(X_tr), dtype=float), index=X_tr.index)\n",
    "\n",
    "    # ---- 決定性最大化パラメータ ----\n",
    "    params = dict(\n",
    "        objective=\"binary\",\n",
    "        learning_rate=0.03,\n",
    "        n_estimators=5000,                    # early_stopping で短縮\n",
    "        num_leaves=31,\n",
    "        # ランダム要素の排除（※再現性を最優先）\n",
    "        subsample=1.0,                        # = bagging_fraction\n",
    "        colsample_bytree=1.0,                # = feature_fraction\n",
    "        # 全シード固定\n",
    "        random_state=seed, bagging_seed=seed, feature_fraction_seed=seed,\n",
    "        data_random_seed=seed, drop_seed=seed,\n",
    "        # 決定論モード & 並列揺らぎ抑止\n",
    "        deterministic=True,\n",
    "        n_jobs=1,                             # = num_threads=1\n",
    "        # クラス不均衡への配慮（元コード踏襲）\n",
    "        class_weight=\"balanced\",\n",
    "        # 追加の安定化（列ワイズ学習を強制）\n",
    "        force_col_wise=True,\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "    best_iters, imps = [], []\n",
    "    splitter = (cv.split(X_tr, y_tr.values, grp_tr) if isinstance(cv, GroupKFold)\n",
    "                else cv.split(X_tr, y_tr.values))\n",
    "\n",
    "    for fold, (tr, va) in enumerate(splitter, 1):\n",
    "        Xtr, Xva = X_tr.iloc[tr].copy(), X_tr.iloc[va].copy()\n",
    "        ytr, yva = y_tr.iloc[tr].values, y_tr.iloc[va].values\n",
    "\n",
    "        # 学習foldのカテゴリ水準を検証foldに合わせる（安定化）\n",
    "        # 学習foldのカテゴリ水準を検証foldに合わせる（安定化）\n",
    "        for c in cat_cols:\n",
    "            if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
    "                Xtr[c] = Xtr[c].astype(\"category\")\n",
    "            if not pd.api.types.is_categorical_dtype(Xva[c]):\n",
    "                Xva[c] = Xva[c].astype(\"category\")\n",
    "            Xtr[c] = Xtr[c].cat.remove_unused_categories()\n",
    "            Xva[c] = Xva[c].cat.set_categories(Xtr[c].cat.categories)\n",
    "\n",
    "\n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            Xtr, ytr,\n",
    "            eval_set=[(Xva, yva)],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(stopping_rounds=200), log_evaluation(0)]\n",
    "        )\n",
    "\n",
    "        oof.iloc[va] = model.predict_proba(Xva)[:, 1]\n",
    "        best_iters.append(model.best_iteration_)\n",
    "        imps.append(pd.DataFrame({\n",
    "            \"feature\": X_tr.columns,\n",
    "            \"importance\": model.booster_.feature_importance(importance_type=\"gain\"),\n",
    "            \"fold\": fold\n",
    "        }))\n",
    "\n",
    "    # ---- CV メトリクス ----\n",
    "    y_true_tr = y_tr.values\n",
    "    oof_pred  = oof.values\n",
    "    cv_auc    = roc_auc_score(y_true_tr, oof_pred)\n",
    "    cv_ap     = average_precision_score(y_true_tr, oof_pred)\n",
    "    prec, rec, thr = precision_recall_curve(y_true_tr, oof_pred)\n",
    "    f1s = 2 * prec * rec / (prec + rec + 1e-12)\n",
    "    bi = int(np.nanargmax(f1s))\n",
    "    best_thr = 0.5 if bi >= len(thr) else float(thr[bi])\n",
    "    cv_f1    = f1_score(y_true_tr, (oof_pred >= best_thr).astype(int))\n",
    "    cv_acc   = accuracy_score(y_true_tr, (oof_pred >= best_thr).astype(int))\n",
    "\n",
    "    # ---- 全学習データで最終学習（CVのbest_iter平均を使用）----\n",
    "    final_ne = int(np.clip(np.mean(best_iters), 100, params[\"n_estimators\"]))\n",
    "    final = LGBMClassifier(**{**params, \"n_estimators\": final_ne})\n",
    "\n",
    "    # テスト側カテゴリを学習側カテゴリに合わせる\n",
    "    for c in cat_cols:\n",
    "        X_tr[c] = X_tr[c].cat.remove_unused_categories()\n",
    "        X_te[c] = X_te[c].astype(\"category\").cat.set_categories(X_tr[c].cat.categories)\n",
    "\n",
    "    final.fit(X_tr, y_tr.values, callbacks=[log_evaluation(0)])\n",
    "\n",
    "    # ---- テスト評価 ----\n",
    "    proba_te = final.predict_proba(X_te)[:, 1]\n",
    "    yhat_te  = (proba_te >= best_thr).astype(int)\n",
    "\n",
    "    te_auc   = roc_auc_score(y_te.values, proba_te)\n",
    "    te_ap    = average_precision_score(y_te.values, proba_te)\n",
    "    te_f1    = f1_score(y_te.values, yhat_te)\n",
    "    te_acc   = accuracy_score(y_te.values, yhat_te)\n",
    "\n",
    "    # 重要度（CV平均）\n",
    "    imp_mean = (pd.concat(imps).groupby(\"feature\")[\"importance\"]\n",
    "                .mean().sort_values(ascending=False).reset_index())\n",
    "\n",
    "    metrics_cv   = {\"AUC\": cv_auc, \"PR_AUC\": cv_ap, \"F1\": cv_f1, \"ACC\": cv_acc,\n",
    "                    \"best_thr\": best_thr, \"best_iters_mean\": float(np.mean(best_iters))}\n",
    "    metrics_test = {\"AUC\": te_auc, \"PR_AUC\": te_ap, \"F1\": te_f1, \"ACC\": te_acc,\n",
    "                    \"thr_used\": best_thr, \"n_estimators\": final_ne}\n",
    "\n",
    "    # 付加: 決定性検証用ハッシュ\n",
    "    feat_hash, feat_meta = fingerprint_features(X_tr, cat_cols)\n",
    "    mod_hash = model_hash(final)\n",
    "\n",
    "    return final, metrics_cv, metrics_test, imp_mean, cat_cols, oof, (X_tr.index, X_te.index), (feat_hash, feat_meta, mod_hash)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07878999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training kind=1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3149]\tvalid_0's auc: 0.698007\tvalid_0's binary_logloss: 0.498626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2741]\tvalid_0's auc: 0.695683\tvalid_0's binary_logloss: 0.506629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4554]\tvalid_0's auc: 0.703178\tvalid_0's binary_logloss: 0.471397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2990]\tvalid_0's auc: 0.70691\tvalid_0's binary_logloss: 0.503786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2831]\tvalid_0's auc: 0.696812\tvalid_0's binary_logloss: 0.507359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/3305051690.py:30: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  c: (list(dfX[c].cat.categories) if (c in dfX.columns and pd.api.types.is_categorical_dtype(dfX[c])) else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training kind=2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[965]\tvalid_0's auc: 0.686496\tvalid_0's binary_logloss: 0.488511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[615]\tvalid_0's auc: 0.683758\tvalid_0's binary_logloss: 0.527448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[675]\tvalid_0's auc: 0.679771\tvalid_0's binary_logloss: 0.515256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[728]\tvalid_0's auc: 0.682479\tvalid_0's binary_logloss: 0.502754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.669427\tvalid_0's binary_logloss: 0.559324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/3305051690.py:30: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  c: (list(dfX[c].cat.categories) if (c in dfX.columns and pd.api.types.is_categorical_dtype(dfX[c])) else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training kind=3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1479]\tvalid_0's auc: 0.790543\tvalid_0's binary_logloss: 0.411178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1527]\tvalid_0's auc: 0.790481\tvalid_0's binary_logloss: 0.414699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1526]\tvalid_0's auc: 0.793307\tvalid_0's binary_logloss: 0.412536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1332]\tvalid_0's auc: 0.78773\tvalid_0's binary_logloss: 0.421024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:52: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xtr[c]):\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/1010783313.py:54: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(Xva[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2035]\tvalid_0's auc: 0.784091\tvalid_0's binary_logloss: 0.391335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/3305051690.py:30: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  c: (list(dfX[c].cat.categories) if (c in dfX.columns and pd.api.types.is_categorical_dtype(dfX[c])) else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   property_kind    cv_AUC  cv_PR_AUC     cv_F1    cv_ACC  thr_used(閾値)  \\\n",
      "0              1  0.699678   0.304062  0.340491  0.753063      0.501803   \n",
      "1              2  0.679321   0.250676  0.307485  0.713424      0.499867   \n",
      "2              3  0.788732   0.318970  0.355822  0.803433      0.547487   \n",
      "\n",
      "   test_AUC  test_PR_AUC   test_F1  test_ACC  \\\n",
      "0  0.721797     0.330851  0.360217  0.739638   \n",
      "1  0.689061     0.257519  0.313707  0.704582   \n",
      "2  0.792587     0.338601  0.364999  0.791534   \n",
      "\n",
      "                       feature_hash                        model_hash  \n",
      "0  5e8dc78d1635ef1f6c9fe56ff261b3b7  ad86b0832baa3d87c4931bdac9102911  \n",
      "1  fd480800ac602ac0093c6fa157b7657d  8a6dd726a79800c56ad6ad711a454e88  \n",
      "2  14089385ccb5dad066aa3ae3315ad5a7  27b1cc9b5e9c7c3b702a43bd9dce2af1  \n",
      "\n",
      "✅ 完了：同一特徴量・同一SEEDなら毎回まったく同じモデル（model_hash）が得られます。\n"
     ]
    }
   ],
   "source": [
    "# ========= 10. 学習→保存→評価 =========\n",
    "summary = []\n",
    "model_registry = {}\n",
    "\n",
    "for kind in [1, 2, 3]:\n",
    "    print(f\"\\n===== Training kind={kind} =====\")\n",
    "    df_kind      = kind_to_df[kind].copy()\n",
    "    feature_cols = kind_to_feats[kind]\n",
    "    category_cols= kind_to_cats[kind]\n",
    "\n",
    "    model, metrics_cv, metrics_test, imp_df, cat_cols_final, oof_series, (idx_tr, idx_te), (feat_hash, feat_meta, mod_hash) = train_eval_lgbm_no_leak(\n",
    "        df_kind, feature_cols, category_cols,\n",
    "        target_col=TARGET, group_col=GROUP_COL, seed=SEED, n_splits=5, test_size=0.2\n",
    "    )\n",
    "\n",
    "    # === 分割情報とメタ保存（再現性トレース） ===\n",
    "    pd.DataFrame({\"train_index\": list(idx_tr)}).to_csv(\n",
    "        os.path.join(OUTPUT_DIR, f\"split_train_index_kind{kind}.csv\"), index=False\n",
    "    )\n",
    "    pd.DataFrame({\"test_index\": list(idx_te)}).to_csv(\n",
    "        os.path.join(OUTPUT_DIR, f\"split_test_index_kind{kind}.csv\"), index=False\n",
    "    )\n",
    "    meta = {\n",
    "        \"kind\": kind,\n",
    "        \"cv_metrics\": metrics_cv,\n",
    "        \"test_metrics\": metrics_test,\n",
    "        \"features\": feature_cols,\n",
    "        \"cat_cols\": cat_cols_final,\n",
    "        \"best_threshold\": metrics_cv[\"best_thr\"],\n",
    "        \"n_estimators_final\": metrics_test[\"n_estimators\"],\n",
    "        \"feature_hash\": feat_hash,\n",
    "        \"model_hash\": mod_hash,\n",
    "        \"versions\": {\n",
    "            \"python\": platform.python_version(),\n",
    "            \"numpy\": np.__version__,\n",
    "            \"pandas\": pd.__version__,\n",
    "        }\n",
    "    }\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"meta_kind{kind}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # === 予測保存（OOF と TEST） ===\n",
    "    # OOF（学習データ内の検証時予測）\n",
    "    pd.DataFrame({\n",
    "        \"index\": oof_series.index,\n",
    "        TARGET: df_kind.loc[oof_series.index, TARGET].astype(int).values,\n",
    "        \"oof_proba\": oof_series.values,\n",
    "        \"oof_pred\":  (oof_series.values >= metrics_cv[\"best_thr\"]).astype(int)\n",
    "    }).to_csv(os.path.join(OUTPUT_DIR, f\"oof_kind{kind}.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # TEST（完全ホールドアウト）\n",
    "    X_te = df_kind.reindex(columns=feature_cols).loc[idx_te].copy()\n",
    "    for c in cat_cols_final:\n",
    "        if c in X_te.columns:\n",
    "            X_te[c] = X_te[c].astype(\"category\")\n",
    "    for c in cat_cols_final:\n",
    "        X_te[c] = X_te[c].cat.set_categories(df_kind.loc[idx_tr, c].astype(\"category\").cat.categories)\n",
    "    proba_te = model.predict_proba(X_te)[:, 1]\n",
    "\n",
    "    kind_names = {1: \"mansion\", 2: \"land\", 3: \"house\"}\n",
    "    kind_name = kind_names[kind]\n",
    "\n",
    "    # ① テストデータ全件テーブル\n",
    "    test_thr = metrics_cv[\"best_thr\"]\n",
    "    pred_te  = (proba_te >= test_thr).astype(int)\n",
    "    y_te     = df_kind.loc[idx_te, TARGET].astype(int).values\n",
    "    pd.DataFrame({\n",
    "        \"ID\": df_kind.loc[idx_te, \"ID\"].values,\n",
    "        TARGET: y_te,\n",
    "        \"proba\": proba_te,\n",
    "        \"pred\":  pred_te,\n",
    "        \"thr_used(閾値)\": test_thr,\n",
    "    }).to_csv(os.path.join(OUTPUT_DIR, f\"test_scores_{kind_name}.csv\"),\n",
    "              index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # ② スコア帯分布 (0.1刻み)\n",
    "    bins = np.linspace(0.0, 1.0, 11)\n",
    "    labels = [f\"{bins[i]:.1f}-{bins[i+1]:.1f}\" for i in range(len(bins)-1)]\n",
    "    counts, _ = np.histogram(proba_te, bins=bins)\n",
    "    ratios = counts / max(len(proba_te), 1)\n",
    "    hist_df = pd.DataFrame({\n",
    "        \"bin_left\":  bins[:-1],\n",
    "        \"bin_right\": bins[1:],\n",
    "        \"label\":     labels,\n",
    "        \"count\":     counts,\n",
    "        \"ratio\":     ratios,\n",
    "    })\n",
    "    hist_df.to_csv(os.path.join(OUTPUT_DIR, f\"test_score_hist_{kind_name}.csv\"),\n",
    "                   index=False, encoding=\"utf-8-sig\")\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(labels, counts)\n",
    "    plt.title(f\"Score histogram (test) - {kind_name}\")\n",
    "    plt.xlabel(\"Score band\"); plt.ylabel(\"Count\"); plt.xticks(rotation=0)\n",
    "    for i, c in enumerate(counts):\n",
    "        plt.text(i, c, str(c), ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"test_score_hist_{kind_name}.png\"), dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "    # 重要度・特徴一覧\n",
    "    imp_df.to_csv(os.path.join(OUTPUT_DIR, f\"importance_kind{kind}.csv\"),\n",
    "                  index=False, encoding=\"utf-8-sig\")\n",
    "    pd.DataFrame({\"feature\": feature_cols}).to_csv(\n",
    "        os.path.join(OUTPUT_DIR, f\"features_kind{kind}.csv\"),\n",
    "        index=False, encoding=\"utf-8-sig\"\n",
    "    )\n",
    "\n",
    "    # モデル保存\n",
    "    joblib.dump(model, os.path.join(MODEL_DIR, f\"lgbm_kind{kind}_v1.pkl\"))\n",
    "\n",
    "    # サマリー\n",
    "    summary.append({\n",
    "        \"property_kind\": kind,\n",
    "        \"cv_AUC\": metrics_cv[\"AUC\"], \"cv_PR_AUC\": metrics_cv[\"PR_AUC\"],\n",
    "        \"cv_F1\": metrics_cv[\"F1\"], \"cv_ACC\": metrics_cv[\"ACC\"],\n",
    "        \"thr_used(閾値)\": metrics_cv[\"best_thr\"],\n",
    "        \"test_AUC\": metrics_test[\"AUC\"], \"test_PR_AUC\": metrics_test[\"PR_AUC\"],\n",
    "        \"test_F1\": metrics_test[\"F1\"], \"test_ACC\": metrics_test[\"ACC\"],\n",
    "        \"feature_hash\": feat_hash, \"model_hash\": mod_hash\n",
    "    })\n",
    "\n",
    "    model_registry[kind] = {\"model\": model, \"features\": feature_cols,\n",
    "                            \"cat_cols\": cat_cols_final, \"metrics_cv\": metrics_cv,\n",
    "                            \"metrics_test\": metrics_test}\n",
    "\n",
    "# === 集計の表示 & 保存 ===\n",
    "summary_df = pd.DataFrame(summary).sort_values(\"property_kind\")\n",
    "print(summary_df)\n",
    "summary_df.to_csv(os.path.join(OUTPUT_DIR, \"metrics_summary_by_kind.csv\"),\n",
    "                  index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# === 一貫性チェック（OOF index / train-test 非交差） ===\n",
    "for kind in model_registry.keys():\n",
    "    df_kind = kind_to_df[kind]\n",
    "    oof_path = os.path.join(OUTPUT_DIR, f\"oof_kind{kind}.csv\")\n",
    "    oof_idx = pd.read_csv(oof_path)[\"index\"].tolist()\n",
    "    assert set(oof_idx).issubset(set(df_kind.index)), f\"kind={kind}: OOFのindexが元dfに含まれていません\"\n",
    "\n",
    "    tr_idx = set(pd.read_csv(os.path.join(OUTPUT_DIR, f\"split_train_index_kind{kind}.csv\"))[\"train_index\"].tolist())\n",
    "    te_idx = set(pd.read_csv(os.path.join(OUTPUT_DIR, f\"split_test_index_kind{kind}.csv\"))[\"test_index\"].tolist())\n",
    "    assert tr_idx.isdisjoint(te_idx), f\"kind={kind}: train/test が交差しています\"\n",
    "\n",
    "print(\"\\n✅ 完了：同一特徴量・同一SEEDなら毎回まったく同じモデル（model_hash）が得られます。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e2568",
   "metadata": {},
   "source": [
    "# SHAP #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d093655",
   "metadata": {},
   "source": [
    "### 関数定義 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f9e01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED: SHAP 入力前に object を category にそろえる安全バンド\n",
    "def ensure_no_object_category(df):\n",
    "    g = df.copy()\n",
    "    for c in g.columns:\n",
    "        if g[c].dtype == \"object\":\n",
    "            g[c] = g[c].astype(\"category\")\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "169fe779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED: probability はやめて、raw + tree_path_dependent で安定運用\n",
    "def make_shap_explainer_raw(model):\n",
    "    import shap\n",
    "    # feature_perturbation=\"tree_path_dependent\" / background は渡さない\n",
    "    return shap.TreeExplainer(\n",
    "        model,\n",
    "        feature_perturbation=\"tree_path_dependent\",\n",
    "        model_output=\"raw\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa808c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/marisa/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, shap, matplotlib.pyplot as plt, os, joblib\n",
    "\n",
    "def make_X_for_kind(df_kind, feature_cols, category_cols):\n",
    "    \"\"\"学習と可視化の両方で使うXを返す。\n",
    "       - 学習用: categoryにキャスト\n",
    "       - 可視化用: すべて数値（カテゴリはcodes）\"\"\"\n",
    "    X = df_kind.reindex(columns=feature_cols).copy()\n",
    "\n",
    "    # まず object を category に（指定外にobjectが残っていても拾う）\n",
    "    for c in X.columns:\n",
    "        if (c in category_cols) or (X[c].dtype == \"object\"):\n",
    "            X[c] = X[c].astype(\"category\")\n",
    "\n",
    "    return X\n",
    "\n",
    "def to_numeric_for_plot(X):\n",
    "    \"\"\"SHAPの可視化向けに、カテゴリ列をcodesへ変換して全列数値にする\"\"\"\n",
    "    Xp = X.copy()\n",
    "    for c in Xp.columns:\n",
    "        dt = Xp[c].dtype\n",
    "        if str(dt).startswith(\"category\"):\n",
    "            Xp[c] = Xp[c].cat.codes\n",
    "        elif dt == \"object\":\n",
    "            # 念のため（残っていたらcategory→codes）\n",
    "            Xp[c] = Xp[c].astype(\"category\").cat.codes\n",
    "    return Xp\n",
    "\n",
    "def shap_all_plots(model, X, kind, sample_size=2000, seed=0,\n",
    "                   topk_depend=5, do_interaction=False):\n",
    "    \"\"\"\n",
    "    SHAP 可視化一括出力（RAWスケールで統一）\n",
    "    - beeswarm / bar / TopK dependence\n",
    "    \"\"\"\n",
    "    import numpy as np, pandas as pd, shap, matplotlib.pyplot as plt, os\n",
    "\n",
    "    # FIXED: 念のため object→category に矯正\n",
    "    X = ensure_no_object_category(X)  # FIXED\n",
    "\n",
    "    # ---- サンプリング（再現性）----\n",
    "    n = min(sample_size, len(X))\n",
    "    idx = np.random.RandomState(seed).choice(X.index, size=n, replace=False)\n",
    "    Xs = X.loc[idx]\n",
    "\n",
    "    # 可視化用（カテゴリ→codes）\n",
    "    def to_numeric_for_plot(df):\n",
    "        g = df.copy()\n",
    "        for c in g.columns:\n",
    "            dt = g[c].dtype\n",
    "            if str(dt).startswith(\"category\"):\n",
    "                g[c] = g[c].cat.codes\n",
    "            elif dt == \"object\":\n",
    "                g[c] = g[c].astype(\"category\").cat.codes\n",
    "        return g\n",
    "    Xs_plot = to_numeric_for_plot(Xs)\n",
    "\n",
    "    # ==== FIXED: raw + tree_path_dependent ====\n",
    "    explainer = make_shap_explainer_raw(model)   # FIXED\n",
    "    sv = explainer(Xs)                           # shap.Explanation (raw)\n",
    "\n",
    "    # ---- 1) summary（beeswarm / bar）----\n",
    "    plt.figure()\n",
    "    shap.summary_plot(sv, Xs_plot, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"shap_beeswarm_kind{kind}.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    shap.summary_plot(sv, Xs_plot, plot_type=\"bar\", show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"shap_bar_kind{kind}.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "    # ---- 2) dependence（TopK）----\n",
    "    mean_abs = np.abs(sv.values).mean(axis=0)\n",
    "    top_feats = (pd.Series(mean_abs, index=Xs.columns)\n",
    "                 .sort_values(ascending=False)\n",
    "                 .head(topk_depend).index.tolist())\n",
    "\n",
    "    for f in top_feats:\n",
    "        plt.figure()\n",
    "        shap.dependence_plot(\n",
    "            ind=f,\n",
    "            shap_values=sv.values,\n",
    "            features=Xs_plot,\n",
    "            feature_names=Xs_plot.columns,\n",
    "            show=False\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUTPUT_DIR, f\"shap_depend_{f}_kind{kind}.png\"), dpi=180)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def save_interaction_scores(model, X, kind, sample_size=2000, seed=SEED):\n",
    "    \"\"\"\n",
    "    全特徴量ペアの相互作用スコアを安定な近似で算出して保存。\n",
    "    score = |corr(SHAP[:, i], X_numeric[:, j])|\n",
    "    \"\"\"\n",
    "    # ---- サンプリング（再現性） ----\n",
    "    rng = np.random.RandomState(seed)\n",
    "    idx = rng.choice(len(X), min(sample_size, len(X)), replace=False)\n",
    "    Xs = X.iloc[idx].copy()\n",
    "\n",
    "    # 可視化/相関計算用にカテゴリを codes に（数値化）\n",
    "    def _to_numeric_for_plot(df):\n",
    "        df2 = df.copy()\n",
    "        for c in df2.columns:\n",
    "            dt = df2[c].dtype\n",
    "            if str(dt).startswith(\"category\"):\n",
    "                df2[c] = df2[c].cat.codes\n",
    "            elif dt == \"object\":\n",
    "                df2[c] = df2[c].astype(\"category\").cat.codes\n",
    "        return df2\n",
    "\n",
    "    Xp = _to_numeric_for_plot(Xs)\n",
    "\n",
    "    # ---- SHAP main effects（raw で高速安定）----\n",
    "    explainer = shap.TreeExplainer(model, model_output=\"raw\")\n",
    "    sv = explainer(Xs)              # shap.Explanation\n",
    "    S = sv.values                   # (n_samples, n_features)\n",
    "    F = Xp.values.astype(float)     # (n_samples, n_features)\n",
    "    cols = X.columns.to_list()\n",
    "    n, d = S.shape\n",
    "\n",
    "    # ---- 相関を一括で計算（ベクトル化）----\n",
    "    # 標準化（分散0は避ける）\n",
    "    S_std = S.std(axis=0, ddof=0)\n",
    "    F_std = F.std(axis=0, ddof=0)\n",
    "    S_std[S_std == 0] = 1.0\n",
    "    F_std[F_std == 0] = 1.0\n",
    "    S_z = (S - S.mean(axis=0)) / S_std   # n×d\n",
    "    F_z = (F - F.mean(axis=0)) / F_std   # n×d\n",
    "\n",
    "    # 相関行列: d×d（各 i の SHAP と各 j の特徴値との相関）\n",
    "    # corr = (S_z^T @ F_z) / (n-1)\n",
    "    C = (S_z.T @ F_z) / max(n - 1, 1)\n",
    "    C = np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    C = np.abs(C)  # 絶対値がスコア\n",
    "\n",
    "    # ---- 上三角分だけをCSVに落とす ----\n",
    "    rows = []\n",
    "    for i in range(d):\n",
    "        for j in range(i + 1, d):\n",
    "            rows.append({\"feat_A\": cols[i], \"feat_B\": cols[j], \"score\": C[i, j]})\n",
    "\n",
    "    df_scores = (pd.DataFrame(rows)\n",
    "                   .sort_values(\"score\", ascending=False)\n",
    "                   .reset_index(drop=True))\n",
    "\n",
    "    out_csv = os.path.join(OUTPUT_DIR, f\"shap_interactions_all_kind{kind}.csv\")\n",
    "    df_scores.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[kind={kind}] 全特徴量ペア {len(df_scores):,} 行の interaction scores を {out_csv} に保存しました。\")\n",
    "\n",
    "\n",
    "#FIXED: 目的変数への寄与度のdependence_plotを追加\n",
    "def shap_dependence_batch(\n",
    "    model,\n",
    "    X,                    # category対応済みの学習用X（= make_X_for_kindの返り値）\n",
    "    kind,\n",
    "    sample_size=2000,\n",
    "    seed=42,\n",
    "    features=\"topk\",      # \"topk\" or \"all\" or list of feature names\n",
    "    topk=20,              # features=\"topk\"のときの数\n",
    "    color_by=None,      # \"auto\" or None or 列名（例：\"BUILDING_AGE_BIN\"）\n",
    "    out_prefix=\"shap_depend\"\n",
    "):\n",
    "    \"\"\"\n",
    "    依存プロットを一括保存。\n",
    "    X軸: 各特徴の値、Y軸: その特徴のSHAP値（目的変数への寄与）\n",
    "    色: 'auto'→ approximate_interactionsでその特徴と相互作用が強い相手を選択\n",
    "        列名→ 常にその列で着色、None→着色なし\n",
    "    \"\"\"\n",
    "    # ---- サンプル抽出（重い計算のため） ----\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n = min(sample_size, len(X))\n",
    "    idx = rng.choice(X.index, size=n, replace=False)\n",
    "    Xs = X.loc[idx].copy()\n",
    "\n",
    "    # 可視化用に数値化（カテゴリ→codes）\n",
    "    Xs_plot = to_numeric_for_plot(Xs)\n",
    "\n",
    "    # ---- SHAP計算（rawで高速安定） ----\n",
    "    explainer = shap.TreeExplainer(model, model_output=\"raw\")\n",
    "    sv = explainer(Xs)                         # shap.Explanation\n",
    "    S = sv.values                              # (n,d)\n",
    "\n",
    "    # ---- 対象特徴の選定 ----\n",
    "    all_feats = list(Xs.columns)\n",
    "    if isinstance(features, list):\n",
    "        target_feats = [f for f in features if f in all_feats]\n",
    "    elif features == \"all\":\n",
    "        target_feats = all_feats\n",
    "    else:\n",
    "        # \"topk\": |SHAP|平均の上位\n",
    "        mean_abs = np.abs(S).mean(axis=0)\n",
    "        target_feats = (pd.Series(mean_abs, index=all_feats)\n",
    "                        .sort_values(ascending=False).head(topk).index.tolist())\n",
    "\n",
    "    # ---- 色付けの相手列を決定 ----\n",
    "    # auto の場合は特徴ごとに approximate_interactions で相手候補を選ぶ\n",
    "    name_to_idx = {c: i for i, c in enumerate(all_feats)}\n",
    "    auto_partner = {}\n",
    "    if color_by == None:\n",
    "        for f in target_feats:\n",
    "            order_idx = shap.utils.approximate_interactions(name_to_idx[f], S, Xs_plot)\n",
    "            # order_idx[0] は自分自身。次点を色付け列に（存在すれば）\n",
    "            if len(order_idx) > 1:\n",
    "                auto_partner[f] = all_feats[order_idx[1]]\n",
    "            else:\n",
    "                auto_partner[f] = None\n",
    "\n",
    "    # ---- 図の出力 ----\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    for f in target_feats:\n",
    "        plt.figure()\n",
    "        if color_by == None:\n",
    "            cb = auto_partner.get(f, None)\n",
    "        elif isinstance(color_by, str):\n",
    "            cb = color_by if color_by in Xs_plot.columns else None\n",
    "        else:\n",
    "            cb = None\n",
    "\n",
    "        shap.dependence_plot(\n",
    "            ind=f,\n",
    "            shap_values=S,\n",
    "            features=Xs_plot,\n",
    "            feature_names=Xs_plot.columns,\n",
    "            interaction_index=(cb if cb in Xs_plot.columns else \"auto\"),  # ない場合はshapに任せる\n",
    "            show=False\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        # ファイル名に色列も入れておくと後で見返しやすい\n",
    "        suffix = f\"_by_{cb}\" if cb else \"\"\n",
    "        plt.savefig(os.path.join(OUTPUT_DIR, f\"{out_prefix}_{f}{suffix}_kind{kind}.png\"), dpi=180)\n",
    "        plt.close()\n",
    "\n",
    "    # どの列で色付けしたかログCSVも残す\n",
    "    log_rows = []\n",
    "    for f in target_feats:\n",
    "        chosen = (auto_partner.get(f) if color_by == \"auto\" else (color_by if isinstance(color_by, str) else None))\n",
    "        log_rows.append({\"feature\": f, \"color_by\": chosen})\n",
    "    pd.DataFrame(log_rows).to_csv(\n",
    "        os.path.join(OUTPUT_DIR, f\"{out_prefix}_colorby_kind{kind}.csv\"),\n",
    "        index=False, encoding=\"utf-8-sig\"\n",
    "    )\n",
    "    print(f\"[kind={kind}] dependence_plot: {len(target_feats)}枚を書き出し（色指定: {color_by}）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b61b6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SHAP 実行ループ（修正版） ===\n",
    "import os, glob, joblib\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)  # FIXED: 出力先の作成（初回でもコケないように）\n",
    "\n",
    "def get_model_for_kind(kind: int):\n",
    "    \"\"\"kind=1/2/3 の LightGBM モデルを取得。\n",
    "    1) model_registry[kind][\"model\"] があればそれ\n",
    "    2) MODEL_DIR 内の pkl/joblib を検索してロード\n",
    "    \"\"\"\n",
    "    # 1) 既に学習済みモデルがメモリにある場合\n",
    "    try:\n",
    "        if \"model_registry\" in globals():\n",
    "            m = model_registry[kind][\"model\"]\n",
    "            if m is not None:\n",
    "                return m\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) ファイルからロード\n",
    "    candidates = []\n",
    "    # よく使う名前\n",
    "    candidates += [\n",
    "        os.path.join(MODEL_DIR, f\"lgbm_kind{kind}_v1.pkl\"),\n",
    "        os.path.join(MODEL_DIR, f\"lgbm_property_kind{kind}.pkl\"),\n",
    "        os.path.join(MODEL_DIR, f\"lgbm_kind{kind}.joblib\"),\n",
    "        os.path.join(MODEL_DIR, f\"lgbm_property_kind{kind}.joblib\"),\n",
    "    ]\n",
    "    # ワイルドカードでも探す\n",
    "    patterns = [\n",
    "        os.path.join(MODEL_DIR, f\"*kind{kind}*.pkl\"),\n",
    "        os.path.join(MODEL_DIR, f\"*kind{kind}*.joblib\"),\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        candidates += glob.glob(pat)\n",
    "\n",
    "    for path in candidates:\n",
    "        if os.path.exists(path):\n",
    "            return joblib.load(path)\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        f\"モデルファイルが見つかりませんでした（kind={kind}）。MODEL_DIR={MODEL_DIR} を確認してください。\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afaf2f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os\n",
    "\n",
    "def dump_category_code_map(X, col, out_dir, kind=None):\n",
    "    \"\"\"\n",
    "    X[col] を category にして、code ↔ label の対応表をCSVで保存する。\n",
    "    - 欠損(NaN)は code = -1 として行を追加\n",
    "    \"\"\"\n",
    "    s = X[col]\n",
    "    if s.dtype != \"category\":\n",
    "        s = s.astype(\"category\")\n",
    "    cats = list(s.cat.categories)\n",
    "    df_map = pd.DataFrame({\n",
    "        \"code\": list(range(len(cats))),\n",
    "        \"label\": cats\n",
    "    })\n",
    "    # NaN（欠損）があれば -1 行を付ける\n",
    "    if s.isna().any():\n",
    "        df_map = pd.concat([pd.DataFrame([{\"code\": -1, \"label\": \"<NA>\"}]), df_map], ignore_index=True)\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    fname = f\"category_codes_{col}.csv\" if kind is None else f\"category_codes_{col}_kind{kind}.csv\"\n",
    "    path = os.path.join(out_dir, fname)\n",
    "    df_map.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"saved: {path}\")\n",
    "    return df_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "877ce96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# バイオリン型のサマリ図（violinが無ければdotに自動フォールバック）\n",
    "# 変更点: 上位 max_display の特徴名リストを返すようにした\n",
    "# ------------------------------------------------------------\n",
    "def plot_summary_beeswarm_violin(model, X, kind, sample_size=3000, seed=0, max_display=25):\n",
    "    import numpy as np, shap, matplotlib.pyplot as plt, os\n",
    "    X = ensure_no_object_category(X)\n",
    "    n = min(sample_size, len(X))\n",
    "    idx = np.random.RandomState(seed).choice(X.index, size=n, replace=False)\n",
    "    Xs = X.loc[idx]\n",
    "    # 可視化用は数値化（category→codes）\n",
    "    Xs_plot = Xs.copy()\n",
    "    for c in Xs_plot.columns:\n",
    "        if str(Xs_plot[c].dtype).startswith(\"category\"):\n",
    "            Xs_plot[c] = Xs_plot[c].cat.codes\n",
    "        elif Xs_plot[c].dtype == \"object\":\n",
    "            Xs_plot[c] = Xs_plot[c].astype(\"category\").cat.codes\n",
    "\n",
    "    explainer = make_shap_explainer_raw(model)\n",
    "    sv = explainer(Xs)\n",
    "\n",
    "    # === 追加: 上位特徴名の算出 ===\n",
    "    # shap.summary_plot は順番を返さないため、ここで mean(|SHAP|) の上位を自前で決定\n",
    "    mean_abs = np.abs(sv.values).mean(axis=0)\n",
    "    # 上位 max_display 個の特徴名（図の並びと合うよう降順）\n",
    "    top_feats = (pd.Series(mean_abs, index=Xs.columns)\n",
    "                 .sort_values(ascending=False)\n",
    "                 .head(max_display)\n",
    "                 .index\n",
    "                 .tolist())\n",
    "\n",
    "    plt.figure()\n",
    "    try:\n",
    "        shap.summary_plot(sv, Xs_plot, plot_type=\"violin\", max_display=max_display, show=False)\n",
    "    except Exception:\n",
    "        shap.summary_plot(sv, Xs_plot, plot_type=\"dot\",    max_display=max_display, show=False)\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"shap_summary_violin_kind{kind}.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "    # === 追加: 使った上位特徴をCSVにも保存（後から再現できるように） ===\n",
    "    pd.Series(top_feats, name=\"feature\").to_csv(\n",
    "        os.path.join(OUTPUT_DIR, f\"top_features_from_violin_kind{kind}.csv\"),\n",
    "        index=False, encoding=\"utf-8-sig\"\n",
    "    )\n",
    "\n",
    "    return top_feats  # ← 追加: 上位リストを返す\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 単一特徴の依存プロット（色付け列は任意）\n",
    "# ------------------------------------------------------------\n",
    "def plot_dependence_one(model, X, kind, feature, color_by=None,\n",
    "                        sample_size=3000, seed=0, jp_labels=False):\n",
    "    import numpy as np, shap, matplotlib.pyplot as plt, os\n",
    "    X = ensure_no_object_category(X)\n",
    "    n = min(sample_size, len(X))\n",
    "    idx = np.random.RandomState(seed).choice(X.index, size=n, replace=False)\n",
    "    Xs = X.loc[idx]\n",
    "    # 可視化用は数値化\n",
    "    Xs_plot = Xs.copy()\n",
    "    for c in Xs_plot.columns:\n",
    "        if str(Xs_plot[c].dtype).startswith(\"category\"):\n",
    "            Xs_plot[c] = Xs_plot[c].cat.codes\n",
    "        elif Xs_plot[c].dtype == \"object\":\n",
    "            Xs_plot[c] = Xs_plot[c].astype(\"category\").cat.codes\n",
    "\n",
    "    explainer = make_shap_explainer_raw(model)\n",
    "    sv = explainer(Xs)\n",
    "\n",
    "    plt.figure()\n",
    "    shap.dependence_plot(\n",
    "        ind=feature,\n",
    "        shap_values=sv.values,\n",
    "        features=Xs_plot,\n",
    "        feature_names=Xs_plot.columns,\n",
    "        interaction_index=(color_by if (color_by and color_by in Xs_plot.columns) else None),\n",
    "        show=False\n",
    "    )\n",
    "    if jp_labels:\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(\"SHAP値（成約への寄与度）\")\n",
    "        plt.title(f\"Dependence Plot: {feature}\")\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"plot_dependence_one_{feature}_kind{kind}.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "def _sanitize(s: str) -> str:\n",
    "    \"\"\"ファイル名に使えない文字をアンダースコアへ\"\"\"\n",
    "    return re.sub(r'[\\\\/:*?\"<>|]+', '_', s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4705ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "TARGET = TARGET  # 既存の目的変数名（例: \"成約フラグ\"）。上で定義済みなので流用\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import get_scorer\n",
    "\n",
    "def _sample_xy_for_speed(X, y, n=5000, seed=42):\n",
    "    \"\"\"計算時間短縮のために最大n件にサンプリング。行数が少なければそのまま返す。\"\"\"\n",
    "    if len(X) <= n:\n",
    "        return X, y\n",
    "    rng = np.random.RandomState(seed)\n",
    "    idx = rng.choice(len(X), size=n, replace=False)\n",
    "    return X.iloc[idx], y.iloc[idx]\n",
    "\n",
    "def run_permutation_importance(model, X, y, *, n_repeats=10, seed=42):\n",
    "    \"\"\"ROC-AUC を指標に Permutation Importance を計算して返す。\"\"\"\n",
    "    r = permutation_importance(\n",
    "        model, X, y,\n",
    "        scoring=get_scorer(\"roc_auc\"),\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=seed,\n",
    "        n_jobs=1,\n",
    "    )\n",
    "    df = (pd.DataFrame({\n",
    "            \"feature\": X.columns,\n",
    "            \"auc_drop_mean\": r.importances_mean,   # 大：その列を壊すとAUCが下がる＝重要\n",
    "            \"auc_drop_std\":  r.importances_std,\n",
    "        })\n",
    "        .sort_values(\"auc_drop_mean\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def save_perm_bar(imp_df, kind, out_dir, fname_png, topn=25):\n",
    "    \"\"\"上位N本の横棒グラフ（AUC drop）を保存。base AUCは描かない。\"\"\"\n",
    "    plot_df = imp_df.head(topn).iloc[::-1]\n",
    "    plt.figure(figsize=(7, 8))\n",
    "    plt.barh(plot_df[\"feature\"], plot_df[\"auc_drop_mean\"])\n",
    "    plt.xlabel(\"AUC drop (higher = more important)\")\n",
    "    plt.title(f\"[kind={kind}] Permutation Importance\")\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(out_dir, fname_png), dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def _load_meta_from_disk(kind):\n",
    "    \"\"\"\n",
    "    学習時に保存済みのメタ情報から\n",
    "    features / cat_cols / test,train index / model を復元。\n",
    "    （model_registry が無いケースのフォールバック）\n",
    "    \"\"\"\n",
    "    # モデル\n",
    "    mdl_path_candidates = [\n",
    "        os.path.join(MODEL_DIR, f\"lgbm_kind{kind}.pkl\"),\n",
    "        os.path.join(MODEL_DIR, f\"lgbm_property_kind{kind}.pkl\"),\n",
    "        os.path.join(MODEL_DIR, f\"lgbm_kind{kind}.joblib\"),\n",
    "        os.path.join(MODEL_DIR, f\"lgbm_property_kind{kind}.joblib\"),\n",
    "    ]\n",
    "    model = None\n",
    "    for p in mdl_path_candidates:\n",
    "        if os.path.exists(p):\n",
    "            model = joblib.load(p); break\n",
    "    if model is None:\n",
    "        raise FileNotFoundError(f\"model file not found for kind={kind}\")\n",
    "\n",
    "    # メタ（features, cat_cols 等）\n",
    "    meta = json.load(open(os.path.join(OUTPUT_DIR, f\"meta_kind{kind}.json\"), \"r\"))\n",
    "    feature_cols = meta[\"features\"]\n",
    "    cat_cols = meta[\"cat_cols\"]\n",
    "\n",
    "    # split index\n",
    "    idx_tr = pd.read_csv(os.path.join(OUTPUT_DIR, f\"split_train_index_kind{kind}.csv\"))[\"train_index\"].tolist()\n",
    "    idx_te = pd.read_csv(os.path.join(OUTPUT_DIR, f\"split_test_index_kind{kind}.csv\"))[\"test_index\"].tolist()\n",
    "    return model, feature_cols, cat_cols, idx_tr, idx_te\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa14f56",
   "metadata": {},
   "source": [
    "### 実行 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4221f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHAP] property_kind=1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:62: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, show=False)\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:68: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, plot_type=\"bar\", show=False)\n",
      "/opt/anaconda3/envs/marisa/lib/python3.13/site-packages/shap/plots/_scatter.py:641: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=figsize)\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:214: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kind=1] dependence_plot: 20枚を書き出し（色指定: None）\n",
      "[kind=1] 全特徴量ペア 1,711 行の interaction scores を /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/shap_interactions_all_kind1.csv に保存しました。\n",
      "[SHAP] property_kind=2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:62: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, show=False)\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:68: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, plot_type=\"bar\", show=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kind=2] dependence_plot: 20枚を書き出し（色指定: None）\n",
      "[kind=2] 全特徴量ペア 1,225 行の interaction scores を /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/shap_interactions_all_kind2.csv に保存しました。\n",
      "[SHAP] property_kind=3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:62: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, show=False)\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:68: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, plot_type=\"bar\", show=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kind=3] dependence_plot: 20枚を書き出し（色指定: None）\n",
      "[kind=3] 全特徴量ペア 1,485 行の interaction scores を /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/shap_interactions_all_kind3.csv に保存しました。\n",
      "完了。OUTPUT_DIR の CSV/PNG を確認してください。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#相互作用の確認\n",
    "\n",
    "for kind in [1, 2, 3]:\n",
    "    print(f\"[SHAP] property_kind={kind} ...\")\n",
    "    df_kind       = kind_to_df[kind].copy()\n",
    "    feature_cols  = kind_to_feats[kind]\n",
    "    category_cols = kind_to_cats[kind]\n",
    "\n",
    "    model = get_model_for_kind(kind)\n",
    "\n",
    "    # --- X を作る（学習 & 可視化向けにカテゴリ化） ---\n",
    "    X_all = make_X_for_kind(df_kind, feature_cols, category_cols)\n",
    "\n",
    "    # FIXED: SHAP は基本「学習データ」で実施（テストは評価専用）\n",
    "    #        既に保存済みの学習インデックスがあればそれを使用。無ければ全体でフォールバック。\n",
    "    split_train_path = os.path.join(OUTPUT_DIR, f\"split_train_index_kind{kind}.csv\")\n",
    "    if os.path.exists(split_train_path):\n",
    "        idx_tr = pd.read_csv(split_train_path)[\"train_index\"].tolist()\n",
    "        # 元DFに存在する行だけに安全に制限\n",
    "        idx_tr = [i for i in idx_tr if i in X_all.index]\n",
    "        if len(idx_tr) == 0:\n",
    "            print(f\"  [WARN] split_train_index_kind{kind}.csv は空か不整合。全体にフォールバックします。\")\n",
    "            X_for_shap = X_all\n",
    "        else:\n",
    "            X_for_shap = X_all.loc[idx_tr]\n",
    "    else:\n",
    "        print(f\"  [INFO] split_train_index_kind{kind}.csv が無いので全体で実施します。\")\n",
    "        X_for_shap = X_all\n",
    "\n",
    "    # --- 既存のサマリ（beeswarm/bar, TopK依存） ---\n",
    "    shap_all_plots(model, X_for_shap, kind, sample_size=2000, seed=SEED, topk_depend=5, do_interaction=False)\n",
    "    #                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "    # FIXED: ここでは相互作用の重い計算は切る（別関数で安定近似をCSV出力するため）\n",
    "\n",
    "    # FIXED: Top20 を相互作用相手を自動色付けで一括保存\n",
    "    shap_dependence_batch(\n",
    "        model, X_for_shap, kind,\n",
    "        sample_size=2000, seed=SEED,\n",
    "        features=\"topk\", topk=20,\n",
    "        color_by=None, out_prefix=\"shap_depend\"\n",
    "    )\n",
    "\n",
    "    # --- 全ペア相互作用スコア（安定近似でCSV） ---\n",
    "    # FIXED: shap_interaction_valuesは使わず、相関ベース近似で全ペアのスコアを保存\n",
    "    save_interaction_scores(model, X_for_shap, kind, sample_size=2000, seed=SEED)\n",
    "\n",
    "print(\"完了。OUTPUT_DIR の CSV/PNG を確認してください。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeaddc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Permutation] property_kind=1 ...\n",
      "  -> saved: perm_importance_auc_full_kind1.csv, perm_importance_auc_top25_kind1.png\n",
      "[Permutation] property_kind=2 ...\n",
      "  -> saved: perm_importance_auc_full_kind2.csv, perm_importance_auc_top25_kind2.png\n",
      "[Permutation] property_kind=3 ...\n",
      "  -> saved: perm_importance_auc_full_kind3.csv, perm_importance_auc_top25_kind3.png\n"
     ]
    }
   ],
   "source": [
    "# ==== Permutation Importance 出力（学習済み前提・後処理／学習データベース） ====\n",
    "for kind in [1, 2, 3]:\n",
    "    print(f\"[Permutation] property_kind={kind} ...\")\n",
    "\n",
    "    df_kind = kind_to_df[kind].copy()\n",
    "\n",
    "    # model_registry があれば優先、無ければ保存物から復元\n",
    "    if \"model_registry\" in globals() and kind in model_registry:\n",
    "        model        = model_registry[kind][\"model\"]\n",
    "        feature_cols = model_registry[kind][\"features\"]\n",
    "        cat_cols     = model_registry[kind][\"cat_cols\"]\n",
    "        idx_tr = pd.read_csv(os.path.join(OUTPUT_DIR, f\"split_train_index_kind{kind}.csv\"))[\"train_index\"].tolist()\n",
    "    else:\n",
    "        # モデルとメタをディスクから復元\n",
    "        model = joblib.load(os.path.join(MODEL_DIR, f\"lgbm_kind{kind}.pkl\"))\n",
    "        meta  = json.load(open(os.path.join(OUTPUT_DIR, f\"meta_kind{kind}.json\"), \"r\"))\n",
    "        feature_cols = meta[\"features\"]\n",
    "        cat_cols     = meta[\"cat_cols\"]\n",
    "        idx_tr = pd.read_csv(os.path.join(OUTPUT_DIR, f\"split_train_index_kind{kind}.csv\"))[\"train_index\"].tolist()\n",
    "\n",
    "    # --- 学習データ（train）を母集団にする ---\n",
    "    X_full = df_kind.reindex(columns=feature_cols).loc[idx_tr].copy()\n",
    "    # 学習側なのでカテゴリ整合は軽微でOK（unusedを落とすだけ）\n",
    "    for c in cat_cols:\n",
    "        if c in X_full.columns:\n",
    "            X_full[c] = X_full[c].astype(\"category\")\n",
    "            X_full[c] = X_full[c].cat.remove_unused_categories()\n",
    "\n",
    "    # 念のため object→category 統一\n",
    "    X_full = ensure_no_object_category(X_full)\n",
    "    y_full = df_kind.loc[idx_tr, TARGET].astype(int)\n",
    "\n",
    "    # --- 5,000件サンプルで Permutation（高速） ---\n",
    "    X_perm, y_perm = _sample_xy_for_speed(X_full, y_full, n=5000, seed=SEED)\n",
    "    imp_df = run_permutation_importance(model, X_perm, y_perm, n_repeats=10, seed=SEED)\n",
    "\n",
    "    # --- 保存（CSVはフル、PNGは上位25のみ） ---\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    csv_path = os.path.join(OUTPUT_DIR, f\"perm_importance_auc_full_kind{kind}.csv\")\n",
    "    png_path = os.path.join(OUTPUT_DIR, f\"perm_importance_auc_top25_kind{kind}.png\")\n",
    "\n",
    "    # ▼ 小数第6位に丸め、文字列化して固定表記\n",
    "    imp_df_fmt = imp_df.copy()\n",
    "    imp_df_fmt[\"auc_drop_mean\"] = imp_df_fmt[\"auc_drop_mean\"].apply(lambda x: f\"{x:.6f}\")\n",
    "    imp_df_fmt[\"auc_drop_std\"]  = imp_df_fmt[\"auc_drop_std\"].apply(lambda x: f\"{x:.6f}\")\n",
    "\n",
    "    imp_df_fmt.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    save_perm_bar(imp_df, kind, OUTPUT_DIR, os.path.basename(png_path), topn=25)\n",
    "\n",
    "    print(f\"  -> saved: {os.path.basename(csv_path)}, {os.path.basename(png_path)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "504e24ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHAP] property_kind=1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:62: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, show=False)\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:68: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, plot_type=\"bar\", show=False)\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/3112753872.py:34: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, plot_type=\"violin\", max_display=max_display, show=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/marisa/lib/python3.13/site-packages/shap/plots/_scatter.py:641: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/3112753872.py:72: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind1.csv\n",
      "  -> saved: shap_importance_meanabs_full_kind1.csv, shap_importance_meanabs_top25_kind1.png\n",
      "[SHAP] property_kind=2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:62: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, show=False)\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:68: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, plot_type=\"bar\", show=False)\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/3112753872.py:34: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, plot_type=\"violin\", max_display=max_display, show=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind2.csv\n",
      "  -> saved: shap_importance_meanabs_full_kind2.csv, shap_importance_meanabs_top25_kind2.png\n",
      "[SHAP] property_kind=3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:62: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, show=False)\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/10461453.py:68: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, plot_type=\"bar\", show=False)\n",
      "/var/folders/g0/2b_vns0j58s8vjrwhmlk88l40000gn/T/ipykernel_13178/3112753872.py:34: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(sv, Xs_plot, plot_type=\"violin\", max_display=max_display, show=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "saved: /Users/okada1015/Desktop/マリサ/marisa/output_model_v1/category_codes_PREFECTURE_kind3.csv\n",
      "  -> saved: shap_importance_meanabs_full_kind3.csv, shap_importance_meanabs_top25_kind3.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== ここから SHAP 実行ループ =====\n",
    "for kind in [1, 2, 3]:\n",
    "    print(f\"[SHAP] property_kind={kind} ...\")\n",
    "    df_kind = kind_to_df[kind].copy()\n",
    "    feature_cols = kind_to_feats[kind]\n",
    "    category_cols = kind_to_cats[kind]\n",
    "\n",
    "    model = get_model_for_kind(kind)\n",
    "    X = make_X_for_kind(df_kind, feature_cols, category_cols)\n",
    "\n",
    "    # 既存の一括出力（beeswarm / bar / TopK 依存 / 全ペア相関）\n",
    "    shap_all_plots(model, X, kind, sample_size=2000, seed=SEED, topk_depend=5, do_interaction=True)\n",
    "    # save_interaction_scores(model, X, kind, sample_size=2000, seed=SEED)\n",
    "\n",
    "    # =========================\n",
    "    # FIXED: 追加の2種類の図を保存\n",
    "    # =========================\n",
    "\n",
    "    # (A) バイオリン型サマリ（図2）\n",
    "    # 修正点: ここで上位25特徴のリストを受け取る\n",
    "    top25_feats = plot_summary_beeswarm_violin(\n",
    "        model, X, kind, sample_size=3000, seed=SEED, max_display=25\n",
    "    )\n",
    "\n",
    "    # 例）PREFECTURE のマッピングを保存\n",
    "    X_safe = ensure_no_object_category(X)   # ← あなたの関数でobject→categoryに統一\n",
    "    dump_category_code_map(X_safe, \"PREFECTURE\", OUTPUT_DIR, kind=kind)\n",
    "\n",
    "    # (B) 単一特徴の依存プロット（図1）\n",
    "    # 修正点: ループに順位を付与し、保存直後にリネームして \"kind-順位.\" を先頭に付ける\n",
    "    for rank, feat in enumerate(top25_feats, start=1):\n",
    "        if feat in X.columns:\n",
    "            plot_dependence_one(\n",
    "                model, X, kind,\n",
    "                feature=feat,\n",
    "                color_by=None,            # 色分けなし\n",
    "                sample_size=3000,\n",
    "                seed=SEED,\n",
    "                jp_labels=False\n",
    "            )\n",
    "        \n",
    "            # 例）PREFECTURE のマッピングを保存\n",
    "            X_safe = ensure_no_object_category(X)   # ← あなたの関数でobject→categoryに統一\n",
    "            dump_category_code_map(X_safe, \"PREFECTURE\", OUTPUT_DIR, kind=kind)\n",
    "\n",
    "            # ▼ ここから追加: リネームで \"kind-順位.\" を先頭に付与\n",
    "            base = f\"plot_dependence_one_{_sanitize(feat)}_kind{kind}.png\"\n",
    "            src  = os.path.join(OUTPUT_DIR, base)\n",
    "            dst  = os.path.join(OUTPUT_DIR, f\"{kind}-{rank}.{base}\")\n",
    "            if os.path.exists(src):\n",
    "                os.replace(src, dst)   # 既存ファイルがあれば置き換え\n",
    "\n",
    "    # (C) SHAP 重要度バー（mean(|SHAP|)でソートした自作版）\n",
    "    # --------------------------------------------------------\n",
    "    # サンプリングして計算を軽く（必要に応じて件数調整）\n",
    "    _n = min(3000, len(X))\n",
    "    _idx = np.random.RandomState(SEED).choice(X.index, size=_n, replace=False)\n",
    "    Xs_cate = ensure_no_object_category(X.loc[_idx].copy())\n",
    "\n",
    "    # 可視化用（カテゴリ→codes の数値化は \"図の色分け用\" だけ。SHAP計算はカテゴリのまま）\n",
    "    Xs_plot = Xs_cate.copy()\n",
    "    for c in Xs_plot.columns:\n",
    "        dt = Xs_plot[c].dtype\n",
    "        if str(dt).startswith(\"category\"):\n",
    "            Xs_plot[c] = Xs_plot[c].cat.codes\n",
    "        elif dt == \"object\":\n",
    "            Xs_plot[c] = Xs_plot[c].astype(\"category\").cat.codes\n",
    "\n",
    "    # SHAP計算（raw + tree_path_dependent）\n",
    "    explainer = make_shap_explainer_raw(model)\n",
    "    sv = explainer(Xs_cate)  # shap.Explanation\n",
    "\n",
    "    # mean(|SHAP|) を算出して降順に\n",
    "    mean_abs = np.abs(sv.values).mean(axis=0)\n",
    "    imp_series = pd.Series(mean_abs, index=Xs_cate.columns).sort_values(ascending=False)\n",
    "    imp_df_shap = (\n",
    "        imp_series\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"feature\", 0: \"mean_abs_shap\"})\n",
    "    )\n",
    "\n",
    "    # 保存（CSVは全特徴、PNGは上位25）\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    csv_path = os.path.join(OUTPUT_DIR, f\"shap_importance_meanabs_full_kind{kind}.csv\")\n",
    "    png_path = os.path.join(OUTPUT_DIR, f\"shap_importance_meanabs_top25_kind{kind}.png\")\n",
    "\n",
    "    # CSV（数値は固定小数で書き出し）\n",
    "    imp_df_csv = imp_df_shap.copy()\n",
    "    imp_df_csv[\"mean_abs_shap\"] = imp_df_csv[\"mean_abs_shap\"].apply(lambda x: f\"{x:.6f}\")\n",
    "    imp_df_csv.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 図（上位25を横棒で、上が最大になるように反転）\n",
    "    topn = 25\n",
    "    plot_df = imp_df_shap.head(topn).iloc[::-1]  # 反転して最大を上に\n",
    "    plt.figure(figsize=(7, 8))\n",
    "    plt.barh(plot_df[\"feature\"], plot_df[\"mean_abs_shap\"])\n",
    "    plt.xlabel(\"mean(|SHAP value|) (average impact on model output magnitude)\")\n",
    "    plt.title(f\"[kind={kind}] SHAP Feature Importance (mean abs)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(png_path, dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"  -> saved: {os.path.basename(csv_path)}, {os.path.basename(png_path)}\")\n",
    "\n",
    "\n",
    "    # ===== ここまで SHAP 実行ループ ====="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf5243",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marisa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
